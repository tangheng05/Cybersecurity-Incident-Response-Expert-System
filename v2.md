High-level summary

Rule-based forward-chaining engine.

Each rule: conditions (set), conclusion (single), certainty factor CF ∈ [0,1].

Facts: input set of symbols (present/absent only).

Rules fire only when all their conditions are present.

Multiple rules can support the same conclusion; CFs are incrementally combined using a specific formula.

The engine records a full trace (fired rules, used facts, skipped rules + missing conditions) to support “why” and “why not” explanations.

Data models (abstract)

Rule:

id: string

conditions: set[string]

conclusion: string

cf: float (0 ≤ cf ≤ 1)

explanation_text: optional string

Factset:

facts: set[string]

ConclusionRecord:

conclusion: string

final_cf: float

supporting_rules: list[{rule_id, rule_cf, matched_conditions}]

used_facts: set[string] (union of matched_conditions)

Trace:

fired_rules: list[{rule_id, matched_conditions, rule_cf, conclusion}]

skipped_rules: list[{rule_id, missing_conditions, conclusion}]

conclusions: map[conclusion → ConclusionRecord]

Core functions & signatures (suggested)
def load_rules() -> List[Rule]:
...

def applicable_rules(facts: Set[str], rules: List[Rule]) -> Tuple[List[Rule], List[SkippedRule]]:
"""
Returns (fired_rules, skipped_rules).
A rule is fired iff rule.conditions ⊆ facts.
Skipped rules include which conditions were missing.
"""

def combine_cfs(cf_old: float, cf_new: float) -> float:
"""
Incremental positive-evidence combination:
return cf_old + cf_new \* (1 - cf_old)
"""

def infer(facts: Set[str], rules: List[Rule]) -> Tuple[Dict[str,float], Trace]:
"""
Performs forward-chaining inference: - Evaluate all rules against facts - For each fired rule: update conclusions[conclusion] by combine_cfs - Build and return Trace containing fired/skipped rules and per-conclusion supporting_rules
"""

Inference algorithm (explicit pseudocode)
function infer(facts, rules):
trace = empty Trace
conclusions = {} # map conclusion -> current CF
support_map = {} # map conclusion -> list of supporting rule entries

    for rule in rules:
        missing = rule.conditions - facts
        if missing == empty:
            // rule fires
            trace.fired_rules.append({rule.id, matched_conditions: rule.conditions, cf: rule.cf, conclusion: rule.conclusion})
            if rule.conclusion in conclusions:
                conclusions[rule.conclusion] = combine_cfs(conclusions[rule.conclusion], rule.cf)
                support_map[rule.conclusion].append({rule.id, rule.cf, matched_conditions: rule.conditions})
            else:
                conclusions[rule.conclusion] = rule.cf
                support_map[rule.conclusion] = [{rule.id, rule.cf, matched_conditions: rule.conditions}]
        else:
            trace.skipped_rules.append({rule.id, missing_conditions: missing, conclusion: rule.conclusion})

    // build ConclusionRecord objects for trace.conclusions
    for concl, cf in conclusions.items():
        trace.conclusions[concl] = {
            conclusion: concl,
            final_cf: cf,
            supporting_rules: support_map[concl],
            used_facts: union of matched_conditions in support_map[concl]
        }

    return conclusions, trace

Explanation API (logic only)

explain(conclusion_id, trace):

If conclusion present in trace.conclusions: return final_cf, supporting_rules, used_facts, and stepwise CF combination (recompute if needed).

Else: return list of skipped rules where conclusion == conclusion_id and their missing conditions (this is a “why not”).

Keep the trace returned by infer() (or cache it per session/request) so explain uses the same trace.

CF combination properties & constraints

Use CF_new = CF_old + CF_rule \* (1 - CF_old) (positive evidence).

CF in [0,1]; ensure numeric stability (clamp if minor floating error).

Avoid assigning CF = 1.0 to normal rules (reserve full confidence only for guaranteed facts).

The combination is effectively associative for incremental application; still, document in code that ordering should not change semantics.

Edge cases & safety rules

Duplicate rules producing same conclusion: allowed — both contribute via combine formula.

Circular rule dependencies: detect cycles if rules can assert new facts during runtime (if design will allow rules to create facts). If only static forward-chaining with input facts, cycles are not created.

No negative evidence or contradiction handling in this logic. If needed, add a negative-evidence model later (specify combination rules).

No normalization across different conclusions — conclusions are independent.

Logging: log every fired/skipped rule with timestamps if auditing required.

Testing checklist (logic-only tests)

Single rule → conclusion CF equals rule CF.

Two supporting rules → final CF equals combine_cfs(cf1, cf2).

Reproducibility: combine_cfs(combine_cfs(cf1,cf2),cf3) == combine_cfs(cf1, combine_cfs(cf2,cf3)) within tolerance.

Skipped rule recorded when conditions missing; explain returns missing conditions for “why not”.

Trace contains matched conditions per supporting rule and final used_facts set.

Numeric clamping: ensure final CF ∈ [0,1] after many combines.

Suggested minimal outputs (engine contract)

infer(facts) → returns:

conclusions: map[string → float] (final CFs)

trace: Trace object (fired_rules, skipped_rules, conclusions map)

explain(conclusion_id, trace) → returns either:

success: {conclusion, final_cf, supporting_rules, used_facts, stepwise_combination}

why_not: {conclusion, candidate_rules_with_missing_conditions}

Implementation notes for the rewriting AI

Keep logic pure and decoupled from persistence / transport:

Core engine = pure functions operating on in-memory data structures.

Persistence (DB) / transport layer (API) should only load rules and facts, call engine, then store/return results.

Make trace data serializable (JSON-friendly).

Make CF function pluggable (so different combination strategies can be swapped in tests).

Keep tests deterministic and small rulebases for unit tests.

Certainty Factor (CF) Logic

Definition: A CF is a confidence value ranging from 0 (no confidence) to 1 (full confidence).

Rule Assignment: Each rule in the knowledge base must be assigned a static CF value indicating its individual strength.

Inference Rule: A rule is triggered (fires) only if all its conditions (antecedents) are present in the user-provided facts.

2. CF Combination Formula
   When multiple independent rules point to the same conclusion, the system must merge their CFs to calculate a final confidence level.

Formula: CF_combined = CF_old + CF_new \* (1 - CF_old).

Example: If Rule 1 (0.8) and Rule 2 (0.6) both support "flu," the calculation is 0.8 + 0.6 \* (1 - 0.8) = 0.92.

3. Explanation Trace Mechanism
   The system must maintain a transparency log (trace) during inference to support two types of explanations:

"Why?" Explanations:

Logic: Record every rule that fired and the specific user facts that matched its conditions.

Output: Show the user the chain of evidence (Rules + Facts) that supported the final conclusion.

"Why Not?" Explanations:

Logic: Log rules that failed to fire because one or more required facts were missing from the input.

Output: Identify exactly which missing facts prevented a specific conclusion from being reached.

4. Implementation Structure

Data Model: Store rules with fields for rule_id, conditions, conclusion, certainty, and a textual explanation string.

Inference Engine Logic:

Collect user facts.

Query the database for rules where conditions match user facts.

Iterate through matching rules:

If the conclusion is new, set the initial CF.

If the conclusion already exists, apply the CF Combination Formula.

Store a rule_trace dictionary mapping each conclusion to the list of rules and CFs that contributed to it.

5. Constraints and Best Practices

Absolutes: Avoid using CF = 1.0 unless a fact is absolutely guaranteed.

Safety: The engine must check for and prevent Infinite Rule Loops caused by circular rule dependencies.

Transparency: Every conclusion must be accompanied by its supporting rules and facts
